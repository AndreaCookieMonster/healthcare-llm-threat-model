---
layout: default
title: October 2025 Additions
description: High-impact LLM vulnerabilities in healthcare surfaced in October 2025.
permalink: /additions/2025-10/
redirect_from:
  - /additions/2025-10/index.md
---

# October 2025 Additions: High-Impact LLM Vulnerabilities in Healthcare

Curated additions not yet captured in the repo’s Top 10 “threat models,” but important for risk
registers, evaluations, and procurement reviews. Each card includes an OWASP LLM Top-10 mapping.

**Entries**

- [Prompt injection on medical VLMs (oncology images)]({{ "/additions/2025-10/vlm-prompt-injection-oncology/" | relative_url }})
- [Prompt injection on surgical video VLMs]({{ "/additions/2025-10/vlm-prompt-injection-surgical-video/" | relative_url }})
- [Adversarial hallucination attacks in clinical decision support]({{ "/additions/2025-10/adversarial-hallucination-attacks-cds/" | relative_url }})
- [Training-data poisoning of medical LLMs]({{ "/additions/2025-10/training-data-poisoning-med-llms/" | relative_url }})
- [Declining medical safety disclaimers in GenAI models]({{ "/additions/2025-10/declining-safety-disclaimers/" | relative_url }})
- [Adversarial re-identification (DIRI) on de-identified clinical text]({{ "/additions/2025-10/patient-reidentification-diri/" | relative_url }})
- [BadCLM: backdoor attacks on clinical language models (EHR)]({{ "/additions/2025-10/badclm-ehr-backdoor/" | relative_url }})
- [LLM-based radiology report anonymization pitfalls]({{ "/additions/2025-10/radiology-report-anonymization-llms/" | relative_url }})

_Note:_ Where a paper is a preprint or review, we still include it when it surfaces a concrete
exploit pattern, operational hazard, or defense relevant to healthcare deployments.
