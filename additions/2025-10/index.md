# October 2025 Additions: High-Impact LLM Vulnerabilities in Healthcare

Curated additions not yet captured in the repo’s Top 10 “threat models,” but important for risk registers, evaluations, and procurement reviews. Each card includes an OWASP LLM Top-10 mapping.

**Entries**
- [Prompt injection on medical VLMs (oncology images)](./vlm-prompt-injection-oncology.md)
- [Prompt injection on surgical video VLMs](./vlm-prompt-injection-surgical-video.md)
- [Adversarial hallucination attacks in clinical decision support](./adversarial-hallucination-attacks-cds.md)
- [Training-data poisoning of medical LLMs](./training-data-poisoning-med-llms.md)
- [Declining medical safety disclaimers in GenAI models](./declining-safety-disclaimers.md)
- [Adversarial re-identification (DIRI) on de-identified clinical text](./patient-reidentification-diri.md)
- [BadCLM: backdoor attacks on clinical language models (EHR)](./badclm-ehr-backdoor.md)
- [LLM-based radiology report anonymization pitfalls](./radiology-report-anonymization-llms.md)

_Note:_ Where a paper is a preprint or review, we still include it when it surfaces a concrete exploit pattern, operational hazard, or defense relevant to healthcare deployments.
